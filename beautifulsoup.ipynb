{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d2cbe3",
   "metadata": {},
   "source": [
    "# Scraping Text from a Web page\n",
    "\n",
    "Now we come to the third way we can retrieve text from the internet. We looked at using a module (yfinance) to retrieve data directly from the internet. We also looked at using a RESTful API (Application Program Interface) to retrieve data froma source by connecting to an API endpoint and requesting data via a HTTP GET. \n",
    "\n",
    "The third way to retrieve data is to scrape it from a webpage. When we scrape from a webpage we are essentailly loading the webpage into a variable, using the requests package. We then use a module called BeautifulSoup4 to extract bits of information from the web page. Let's take a look at a webpage from the Ramapo Website. Specifically we want to look at the academic program offerings at ASB. We can load the webpage in our browswer and see 14 Academic programs offered at the Ansfield School of Business. \n",
    "![](ramapo_ASB.JPG)\n",
    "- Accounting\n",
    "- Accounting (4+1 BS-MS)\n",
    "- Accounting (MSAC)\n",
    "- Business Analytics\n",
    "- Economics\n",
    "- Entrepreneurship\n",
    "- Finance\n",
    "- Human Resources Management\n",
    "- Information Technology Management\n",
    "- International Business\n",
    "- Management\n",
    "- Marketing\n",
    "- Master of Business Administration (MBA)\n",
    "- Sports Management\n",
    "\n",
    "Wouldn't it be nice to be able to retrieve these academic programs and be able to use them in our programs if we wanted to ?\n",
    "Without the data source for this list and if Ramapo did not have an API for us to query, we would resort to webscraping it to retrieve the list Let's look at the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f880b47",
   "metadata": {},
   "source": [
    "### Setting up our Environment\n",
    "We are going to import BeautfulSoup from the bs4 module and also requests. \n",
    "Requests will handle the communication request for our http call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50bf98",
   "metadata": {},
   "source": [
    "Once these modules are available for use. we can start to explore the page. the url for the ASB website is\n",
    "https://www.ramapo.edu/asb/. The first step is to load the page in a modern browser like Chrome. This will allow us to look at the page and see where to target the web scrape. As shown in the screen capture above, we are looking to create a list containing all of the academic programs ASB has to offer. The key to screen scraping is to get a good understanding of how the page was created in html. Understanding the overall structure of the page, some basic html tags will help you figure out how to retrieve the data. To properly scrape the page, you will have to explore the html using the inspect option. Since we are using a Chrome browser in our example, the inspect option is available by clicking on an object oin the scrren, selecting the right mouse key and selecting inspect. The inspection window appears and displays the code on the page. \n",
    "\n",
    "![](ramapo_ASB2.JPG)\n",
    "\n",
    "\n",
    "by highlighting the element on the page we want to examine, the inspection window automatically goes to this part of the page, showing the code for the hgihlighted element. Closer examination reveals the highlighted word Accounting is in an html tag  \\<h3\\>.  Further investigation reveals that each of the items we want to retrieve are all in \\<h3\\> tags. If we traverse up the tree, we also notice that each of our \\<h3\\> tags are under a \\<div\\> tag with an id field called \"row-courses\". The ID field of the \\<div\\> tag is perfect as it is something we can use Beautfiul soup to find and help us to parse it out. \n",
    "    \n",
    "![](ramapo_ASB3.JPG)\n",
    "\n",
    "Let's continue with our environment setup by creating a variable to hold our URL for requests and load the page into a variable using requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef721af",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= \"https://www.ramapo.edu/asb/\"  #My url\n",
    "page = requests.get(URL) # My web page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99a8fb",
   "metadata": {},
   "source": [
    "The code above stores our URL for the ASB page and allows the page variable to point to the html page returned from our requests.  Print the page variable out and make sure we get a code 200 , then print the type out to verify page is the response of the requests call. Finally print the text of page to see what the return htlm looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page)\n",
    "print (type(page))\n",
    "print(page.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d3e5e",
   "metadata": {},
   "source": [
    "As you can see the html which returns is really a jumble of code and hard to read. So next let's work on the return html by using the BeautifulSoup module calling it within th variable soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef957a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\") # soupify the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32297954",
   "metadata": {},
   "source": [
    "Once the page has been \"soupified\", we can ask now begin to scrape the items we need from the page> Remember the \"row-courses\" id tag? We will ask BeautifulSoup to look for everyting with the id=\"row-courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d832270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags= soup.find(id=\"row-courses\") # find tags with the id text. \n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87711ed",
   "metadata": {},
   "source": [
    "Executing the print(tags) statement outputs the data which is everything within the \\<div\\> tag. It is a bit hard to read isn't it? We can use the .prettify() method to show an easier to read output. Run the next print statement and observe the results. It is much easier to see the return html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tags.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead942f",
   "metadata": {},
   "source": [
    "Scroll through the results above and you will see that each of the academic programs are just as we noted above, between the \\<h3\\> tags.  Now all we have to do is to get all of the \\<h3\\> tags by using the .find() or .find_all() methods.  Using the .find() method will find the first \\<h3\\> tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279121db",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_program =tags.find(\"h3\") # finds the first tag\n",
    "print(academic_program)\n",
    "print (type(academic_program))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf08f7",
   "metadata": {},
   "source": [
    "Using .find_all() will find all of the \\<h3\\> tags. The data type of the variable will be a BeautifulSoup 4 ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_programs = tags.find_all(\"h3\") # now use the tags found to find the <h3>. This returns a BS4 result set\n",
    "print(academic_programs)\n",
    "print (type(academic_programs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9afe2",
   "metadata": {},
   "source": [
    "While academic_programs is also a bs4.element.ResultSet, we can treat it like a list and display particular items with an offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(academic_programs[0])\n",
    "print(academic_programs[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e00293",
   "metadata": {},
   "source": [
    "And as with any list, we can iterate through it to display each \\<h3\\> tag on a separate line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in academic_programs:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d3e59",
   "metadata": {},
   "source": [
    "The only thing left is for us to only print the contnets of the \\<h3\\> tag. We can do this by specifying the text in the print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(academic_programs[0].text)\n",
    "print(academic_programs[5].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in academic_programs:\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e493644",
   "metadata": {},
   "source": [
    "### What Can We Do With The Scraped Data ?\n",
    "\n",
    "As you can see we were able to scrape the academic programs directly from the ASB page. We can create an empty list and append each tag's text to the list as we iterate through the tag's contents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "academics =[] # create an empty list\n",
    "for tag in academic_programs: #iterate through the tags\n",
    "   academics.append(tag.text) # append the tag's text into the list\n",
    "print(type(academics)) # check to see our list is indeed a list\n",
    "print (academics) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458eff7e",
   "metadata": {},
   "source": [
    "We may optionally want to ensure our academic programs are not changable (immutable) by converting it to a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1184176",
   "metadata": {},
   "outputs": [],
   "source": [
    "myTuple= tuple(academics) #convert the list to a tuple\n",
    "print (type(myTuple)) # check to see the new tuple is indeed a tuple\n",
    "print(myTuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fad23",
   "metadata": {},
   "source": [
    "Let get all of the degree types as well. If you scroll above in the return of the tags, the degree types seem to be located with the \\<h4\\> tags. Let's go get those as well and append them to a list called degrees\\[\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_tags =tags.find_all(\"h4\")\n",
    "print(degree_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f79fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees=[]\n",
    "for tag in degree_tags: #iterate through the tags\n",
    "   degrees.append(tag.text) # append the tag's text into the list\n",
    "print(type(degrees)) # check to see our list is indeed a list\n",
    "print (degrees) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53425f2",
   "metadata": {},
   "source": [
    "Let's create a dictionary from the two lists, with academics\\[\\] being the keys and degrees\\[\\] being th values. Remeber our old friend zip ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keys = academics[]\",\"\\n\",academics,\"\\n\")\n",
    "print(\"values = degrees[]\", \"\\n\",degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a787ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_dict= dict(zip(academics,degrees))\n",
    "print (type(program_dict))\n",
    "print(program_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323da32b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for keys in program_dict:\n",
    "    print(keys,\":\", program_dict[keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f06e4",
   "metadata": {},
   "source": [
    "We can use  the data in our programs as data to answer some questions about ASB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of academic programs offered by the Ansfield School of Business is {len(myTuple)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739921a5",
   "metadata": {},
   "source": [
    "We can also write the lists out to a csv (Comma Separated Value) file which can be opened by Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "headers=[\"Academic Program\", \"Degrees\"]\n",
    "\n",
    "with open('asb2.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(zip(academics, degrees))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bc4c7",
   "metadata": {},
   "source": [
    "we can open the file using python and read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfda206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"asb2.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "      print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301084f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
